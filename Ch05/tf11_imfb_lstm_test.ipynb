{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "날짜 : 2020/08/20\n",
    "이름 : 이태훈\n",
    "내용 : LSTM imdb 텍스트 분석 실습하기\n",
    "\"\"\"\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 로드하기\n",
    "(imdb_train_data, imdb_train_label), (imdb_test_data, imdb_test_label) = imdb.load_data(num_words=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n",
      "(25000,) (25000,)\n",
      "the as you with out themselves powerful and and their becomes and had and of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every and and movie except her was several of enough more with is now and film as you of and and unfortunately of you than him that with out themselves her get for was and of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of and and with heart had and they of here that with her serious to have does when from why what have and they is you that isn't one will very to as itself with other and in of seen over and for anyone of and br and to whether from than out themselves history he name half some br of and and was two most of mean for 1 any an and she he should is thought and but of script you not while history he heart to real at and but when from one bit then have two of script their with her and most that with wasn't to with and acting watch an for with and film want an "
     ]
    }
   ],
   "source": [
    "# 데이터 확인하기\n",
    "print(imdb_train_data.shape, imdb_train_label.shape)\n",
    "print(imdb_test_data.shape, imdb_test_label.shape)\n",
    "imdb_train_data[0]\n",
    "#imdb_train_label\n",
    "\n",
    "# 시퀀스데이터 영어 문장으로 변환\n",
    "imdb_get_word_index = {}\n",
    "\n",
    "for word, value in imdb.get_word_index().items():\n",
    "    imdb_get_word_index[value] = word\n",
    "    \n",
    "for w in imdb_train_data[0]:\n",
    "    print(imdb_get_word_index[w], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "패딩 전 :  218\n",
      "패딩 전 :  189\n",
      "패딩 후 :  500\n",
      "패딩 후 :  500\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리(데이터를 동일한 길이로 맞추기)\n",
    "\n",
    "print('패딩 전 : ', len(imdb_train_data[0]))\n",
    "print('패딩 전 : ', len(imdb_train_data[1]))\n",
    "pad_imdb_train_data = pad_sequences(imdb_train_data, maxlen=500, padding='pre')\n",
    "pad_imdb_test_data = pad_sequences(imdb_test_data, maxlen=500, padding='pre')\n",
    "\n",
    "print('패딩 후 : ', len(pad_imdb_train_data[0]))\n",
    "print('패딩 후 : ', len(pad_imdb_train_data[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=1000, output_dim=32))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설정하기\n",
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 0.5969 - acc: 0.6163 - val_loss: 0.6236 - val_acc: 0.6152\n",
      "Epoch 2/100\n",
      "625/625 [==============================] - 43s 69ms/step - loss: 0.6105 - acc: 0.6041 - val_loss: 0.6092 - val_acc: 0.6184\n",
      "Epoch 3/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.5844 - acc: 0.6259 - val_loss: 0.5952 - val_acc: 0.6212\n",
      "Epoch 4/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.5778 - acc: 0.6318 - val_loss: 0.6039 - val_acc: 0.6224\n",
      "Epoch 5/100\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 0.5758 - acc: 0.6289 - val_loss: 0.6070 - val_acc: 0.6061\n",
      "Epoch 6/100\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 0.5737 - acc: 0.6335 - val_loss: 0.6066 - val_acc: 0.6216\n",
      "Epoch 7/100\n",
      "625/625 [==============================] - 43s 69ms/step - loss: 0.5856 - acc: 0.6252 - val_loss: 0.6134 - val_acc: 0.6150: 1s\n",
      "Epoch 8/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.5860 - acc: 0.6283 - val_loss: 0.6057 - val_acc: 0.6175\n",
      "Epoch 9/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.5823 - acc: 0.6317 - val_loss: 0.6089 - val_acc: 0.6099\n",
      "Epoch 10/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.6118 - acc: 0.5987 - val_loss: 0.6190 - val_acc: 0.6111\n",
      "Epoch 11/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.5724 - acc: 0.6332 - val_loss: 0.5964 - val_acc: 0.6228\n",
      "Epoch 12/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.5667 - acc: 0.6377 - val_loss: 0.5926 - val_acc: 0.6200\n",
      "Epoch 13/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.5628 - acc: 0.6423 - val_loss: 0.5960 - val_acc: 0.6242\n",
      "Epoch 14/100\n",
      "625/625 [==============================] - 43s 69ms/step - loss: 0.5772 - acc: 0.6347 - val_loss: 0.6038 - val_acc: 0.6233\n",
      "Epoch 15/100\n",
      "625/625 [==============================] - 43s 69ms/step - loss: 0.5631 - acc: 0.6395 - val_loss: 0.6108 - val_acc: 0.6209\n",
      "Epoch 16/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.6183 - acc: 0.6013 - val_loss: 0.6168 - val_acc: 0.6125\n",
      "Epoch 17/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.6019 - acc: 0.6147 - val_loss: 0.6054 - val_acc: 0.6132\n",
      "Epoch 18/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.5867 - acc: 0.6205 - val_loss: 0.5985 - val_acc: 0.6169\n",
      "Epoch 19/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.5774 - acc: 0.6291 - val_loss: 0.5938 - val_acc: 0.6212\n",
      "Epoch 20/100\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 0.5716 - acc: 0.6288 - val_loss: 0.5909 - val_acc: 0.6230\n",
      "Epoch 21/100\n",
      "625/625 [==============================] - 43s 69ms/step - loss: 0.5677 - acc: 0.6338 - val_loss: 0.5927 - val_acc: 0.6225\n",
      "Epoch 22/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.5646 - acc: 0.6369 - val_loss: 0.5981 - val_acc: 0.6221\n",
      "Epoch 23/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.5630 - acc: 0.6377 - val_loss: 0.6005 - val_acc: 0.6184: 1s \n",
      "Epoch 24/100\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 0.5617 - acc: 0.6339 - val_loss: 0.6245 - val_acc: 0.6138\n",
      "Epoch 25/100\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 0.5646 - acc: 0.6361 - val_loss: 0.6004 - val_acc: 0.6202\n",
      "Epoch 26/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.5573 - acc: 0.6402 - val_loss: 0.6022 - val_acc: 0.6197\n",
      "Epoch 27/100\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 0.5535 - acc: 0.6468 - val_loss: 0.6031 - val_acc: 0.6198\n",
      "Epoch 28/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.5513 - acc: 0.6443 - val_loss: 0.6055 - val_acc: 0.6191\n",
      "Epoch 29/100\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 0.5507 - acc: 0.6463 - val_loss: 0.6035 - val_acc: 0.6183\n",
      "Epoch 30/100\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 0.5482 - acc: 0.6423 - val_loss: 0.6253 - val_acc: 0.6179\n",
      "Epoch 31/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.5460 - acc: 0.6447 - val_loss: 0.6181 - val_acc: 0.6193\n",
      "Epoch 32/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.5447 - acc: 0.6502 - val_loss: 0.6192 - val_acc: 0.6178\n",
      "Epoch 33/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.5422 - acc: 0.6497 - val_loss: 0.6331 - val_acc: 0.6187\n",
      "Epoch 34/100\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 0.5406 - acc: 0.6506 - val_loss: 0.6260 - val_acc: 0.6163\n",
      "Epoch 35/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.5388 - acc: 0.6489 - val_loss: 0.6211 - val_acc: 0.6183\n",
      "Epoch 36/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.5385 - acc: 0.6519 - val_loss: 0.6267 - val_acc: 0.6167\n",
      "Epoch 37/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.5378 - acc: 0.6518 - val_loss: 0.6438 - val_acc: 0.6125\n",
      "Epoch 38/100\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 0.5420 - acc: 0.6492 - val_loss: 0.6245 - val_acc: 0.6127\n",
      "Epoch 39/100\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 0.5362 - acc: 0.6504 - val_loss: 0.6333 - val_acc: 0.6150\n",
      "Epoch 40/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.5336 - acc: 0.6540 - val_loss: 0.6411 - val_acc: 0.6151\n",
      "Epoch 41/100\n",
      "625/625 [==============================] - 43s 69ms/step - loss: 0.5336 - acc: 0.6506 - val_loss: 0.6442 - val_acc: 0.6163\n",
      "Epoch 42/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.5303 - acc: 0.6534 - val_loss: 0.6367 - val_acc: 0.6154\n",
      "Epoch 43/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.5278 - acc: 0.6539 - val_loss: 0.6461 - val_acc: 0.6169\n",
      "Epoch 44/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.5268 - acc: 0.6560 - val_loss: 0.6488 - val_acc: 0.6160\n",
      "Epoch 45/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.5287 - acc: 0.6544 - val_loss: 0.6508 - val_acc: 0.6165\n",
      "Epoch 46/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.5251 - acc: 0.6526 - val_loss: 0.6438 - val_acc: 0.6160\n",
      "Epoch 47/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.5228 - acc: 0.6601 - val_loss: 0.6404 - val_acc: 0.6145\n",
      "Epoch 48/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.5249 - acc: 0.6545 - val_loss: 0.6554 - val_acc: 0.6145\n",
      "Epoch 49/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.5241 - acc: 0.6552 - val_loss: 0.6640 - val_acc: 0.6151\n",
      "Epoch 50/100\n",
      "625/625 [==============================] - 43s 69ms/step - loss: 0.5181 - acc: 0.6595 - val_loss: 0.6559 - val_acc: 0.6132\n",
      "Epoch 51/100\n",
      "625/625 [==============================] - 43s 69ms/step - loss: 0.5196 - acc: 0.6549 - val_loss: 0.6512 - val_acc: 0.6138\n",
      "Epoch 52/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.5163 - acc: 0.6612 - val_loss: 0.6686 - val_acc: 0.6146\n",
      "Epoch 53/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.5188 - acc: 0.6587 - val_loss: 0.6527 - val_acc: 0.6138\n",
      "Epoch 54/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.5141 - acc: 0.6617 - val_loss: 0.6666 - val_acc: 0.6101\n",
      "Epoch 55/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.5122 - acc: 0.6607 - val_loss: 0.6808 - val_acc: 0.6127\n",
      "Epoch 56/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.5117 - acc: 0.6656 - val_loss: 0.6776 - val_acc: 0.6103\n",
      "Epoch 57/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.5102 - acc: 0.6653 - val_loss: 0.6572 - val_acc: 0.6138\n",
      "Epoch 58/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.5086 - acc: 0.6668 - val_loss: 0.6675 - val_acc: 0.6144\n",
      "Epoch 59/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.5086 - acc: 0.6620 - val_loss: 0.6693 - val_acc: 0.6088\n",
      "Epoch 60/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.5095 - acc: 0.6632 - val_loss: 0.6408 - val_acc: 0.6093\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 42s 67ms/step - loss: 0.5118 - acc: 0.6659 - val_loss: 0.6867 - val_acc: 0.6081\n",
      "Epoch 62/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.5101 - acc: 0.6624 - val_loss: 0.6907 - val_acc: 0.6120\n",
      "Epoch 63/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.5016 - acc: 0.6672 - val_loss: 0.7041 - val_acc: 0.6091\n",
      "Epoch 64/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.4985 - acc: 0.6701 - val_loss: 0.7208 - val_acc: 0.6059\n",
      "Epoch 65/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.4985 - acc: 0.6707 - val_loss: 0.7143 - val_acc: 0.6085\n",
      "Epoch 66/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.4992 - acc: 0.6666 - val_loss: 0.7057 - val_acc: 0.6075\n",
      "Epoch 67/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.5012 - acc: 0.6659 - val_loss: 0.7137 - val_acc: 0.6080\n",
      "Epoch 68/100\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 0.4950 - acc: 0.6684 - val_loss: 0.7382 - val_acc: 0.6066\n",
      "Epoch 69/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.4963 - acc: 0.6701 - val_loss: 0.7277 - val_acc: 0.6059\n",
      "Epoch 70/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.5005 - acc: 0.6674 - val_loss: 0.7127 - val_acc: 0.6080\n",
      "Epoch 71/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.5277 - acc: 0.6590 - val_loss: 0.6649 - val_acc: 0.6053\n",
      "Epoch 72/100\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 0.5264 - acc: 0.6609 - val_loss: 0.6867 - val_acc: 0.6096\n",
      "Epoch 73/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.5010 - acc: 0.6690 - val_loss: 0.7046 - val_acc: 0.6069\n",
      "Epoch 74/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.4933 - acc: 0.6695 - val_loss: 0.7167 - val_acc: 0.6067\n",
      "Epoch 75/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.4915 - acc: 0.6712 - val_loss: 0.7141 - val_acc: 0.6089\n",
      "Epoch 76/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.4934 - acc: 0.6682 - val_loss: 0.7199 - val_acc: 0.6051\n",
      "Epoch 77/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.4881 - acc: 0.6731 - val_loss: 0.7195 - val_acc: 0.6052\n",
      "Epoch 78/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.4885 - acc: 0.6700 - val_loss: 0.7444 - val_acc: 0.6057\n",
      "Epoch 79/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.4882 - acc: 0.6749 - val_loss: 0.7433 - val_acc: 0.6031\n",
      "Epoch 80/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.4924 - acc: 0.6702 - val_loss: 0.7408 - val_acc: 0.6003\n",
      "Epoch 81/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.5072 - acc: 0.6639 - val_loss: 0.7197 - val_acc: 0.6019\n",
      "Epoch 82/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.4979 - acc: 0.6666 - val_loss: 0.7485 - val_acc: 0.6029\n",
      "Epoch 83/100\n",
      "141/625 [=====>........................] - ETA: 29s - loss: 0.4896 - acc: 0.6774"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-57c8cd5b4832>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 모델 학습하기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m model.fit(pad_imdb_train_data, \n\u001b[0m\u001b[0;32m      3\u001b[0m           \u001b[0mimdb_train_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델 학습하기\n",
    "model.fit(pad_imdb_train_data, \n",
    "          imdb_train_label,\n",
    "          batch_size=32, \n",
    "          epochs=100,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 17s 22ms/step - loss: 0.6014 - acc: 0.6168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6013575196266174, 0.6168457865715027]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가하기\n",
    "model.evaluate(pad_imdb_test_data, imdb_test_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
