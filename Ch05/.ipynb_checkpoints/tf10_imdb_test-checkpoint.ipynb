{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "날짜 : 2020/08/20\n",
    "이름 : 이태훈\n",
    "내용 : RNN imdb 텍스트 분석 실습하기\n",
    "\"\"\"\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 로드하기\n",
    "(imdb_train_data, imdb_train_label), (imdb_test_data, imdb_test_label) = imdb.load_data(num_words=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n",
      "(25000,) (25000,)\n",
      "the as you with out themselves powerful and and their becomes and had and of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every and and movie except her was several of enough more with is now and film as you of and and unfortunately of you than him that with out themselves her get for was and of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of and and with heart had and they of here that with her serious to have does when from why what have and they is you that isn't one will very to as itself with other and in of seen over and for anyone of and br and to whether from than out themselves history he name half some br of and and was two most of mean for 1 any an and she he should is thought and but of script you not while history he heart to real at and but when from one bit then have two of script their with her and most that with wasn't to with and acting watch an for with and film want an "
     ]
    }
   ],
   "source": [
    "# 데이터 확인하기\n",
    "print(imdb_train_data.shape, imdb_train_label.shape)\n",
    "print(imdb_test_data.shape, imdb_test_label.shape)\n",
    "imdb_train_data[0]\n",
    "#imdb_train_label\n",
    "\n",
    "# 시퀀스데이터 영어 문장으로 변환\n",
    "imdb_get_word_index = {}\n",
    "\n",
    "for word, value in imdb.get_word_index().items():\n",
    "    imdb_get_word_index[value] = word\n",
    "    \n",
    "for w in imdb_train_data[0]:\n",
    "    print(imdb_get_word_index[w], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "패딩 전 :  218\n",
      "패딩 전 :  189\n",
      "패딩 후 :  500\n",
      "패딩 후 :  500\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리(데이터를 동일한 길이로 맞추기)\n",
    "\n",
    "print('패딩 전 : ', len(imdb_train_data[0]))\n",
    "print('패딩 전 : ', len(imdb_train_data[1]))\n",
    "pad_imdb_train_data = pad_sequences(imdb_train_data, maxlen=500, padding='pre')\n",
    "pad_imdb_test_data = pad_sequences(imdb_test_data, maxlen=500, padding='pre')\n",
    "\n",
    "print('패딩 후 : ', len(pad_imdb_train_data[0]))\n",
    "print('패딩 후 : ', len(pad_imdb_train_data[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=1000, output_dim=32))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설정하기\n",
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.6687 - acc: 0.5623 - val_loss: 0.6851 - val_acc: 0.5358\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.6711 - acc: 0.5606 - val_loss: 0.6821 - val_acc: 0.5433\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.6590 - acc: 0.5706 - val_loss: 0.6370 - val_acc: 0.6034\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.6735 - acc: 0.5404 - val_loss: 0.6901 - val_acc: 0.5181\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.6889 - acc: 0.5217 - val_loss: 0.6874 - val_acc: 0.5313\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.6843 - acc: 0.5353 - val_loss: 0.6800 - val_acc: 0.5450\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.6606 - acc: 0.5796 - val_loss: 0.6859 - val_acc: 0.5431\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 26s 42ms/step - loss: 0.6613 - acc: 0.5749 - val_loss: 0.6550 - val_acc: 0.5845\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.6466 - acc: 0.5908 - val_loss: 0.6577 - val_acc: 0.5851\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.6447 - acc: 0.5904 - val_loss: 0.6787 - val_acc: 0.5368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19867f16760>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습하기\n",
    "model.fit(pad_imdb_train_data, \n",
    "          imdb_train_label,\n",
    "          batch_size=32, \n",
    "          epochs=10,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 10s 13ms/step - loss: 0.6802 - acc: 0.5314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6802253723144531, 0.5314115881919861]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가하기\n",
    "model.evaluate(pad_imdb_test_data, imdb_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측하기\n",
    "simple_text = ['I love this movie', 'It is waste of time']\n",
    "result = model.predict(simple_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
